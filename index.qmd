---
title: "U.S. Egg Production Analysis Using Linear Mixed Models"
subtitle: "An Exploration Across States and Months"
author: "Rose Dalton (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib 
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!

Nice report!
:::

## Introduction

Statistical methods for comparing differences between groups have long served as a cornerstone of empirical research across the natural and social sciences. Foundational tools such as t-tests, analysis of variance (ANOVA), and linear regression provided early mechanisms for evaluating mean differences and variance relationships under specific conditions. However, as research designs grew more complex, incorporating repeated measurements, nested data structures, and unbalanced datasets, the limitations of traditional techniques became increasingly apparent. These methodological pressures contributed to the development of linear mixed-effects models (LMMs), which extend classical linear modeling by incorporating both fixed and random sources of variation within hierarchical data structures. The purpose of this review is to examine how LMMs came to prominent usage, the associated benefits and limitations, and how this method may be applied to this capstone project.

Formal statistical tests for group comparisons experienced widespread growth in the early twentieth century. Sir Ronald Fisher’s Statistical Methods for Research Workers (1925) was one of the earliest compilations of comparison analyses such as t-tests, the analysis of variance (ANOVA), the maximum likelihood estimation, and experimental design for correlation studies (@huitema2025fisher). Building on this groundwork, Henderson (1953) advanced methods for estimating variance and covariance components in unbalanced agricultural datasets. His work demonstrated how linear models could utilize variance elements from both fixed and random factors, providing unbiased estimates even among unbalanced group structures. These contributions laid critical groundwork for the development of modern mixed-effects modeling.

Traditional approaches such as ANOVA and simple regression perform optimally under assumptions of independence, normality, and balanced groupings (@henderson1953variance). Violations to the general schema — including repeated measures, nested clustering, and missing data — can compromise inference (@brown2021introduction). Linear mixed-effects models address these limitations by modeling fixed population-level effects alongside random group-level deviations within a single framework. This hierarchical variance structure allows LMMs to account for correlated observations while improving estimate stability through partial pooling, where group estimates are shrunk toward the overall mean when data are limited or missing(@meteyard2020best).

This structure endows LMMs with considerable flexibility. @schielzeth2020robustness demonstrated that fixed-effect variance estimates remain largely unbiased under assumption violations such as skewness, heteroskedasticity, and bimodality, though precision may decline. Despite these advantages, LMMs introduce analytical complexities. Model specification — particularly the selection of random-effects representation terms— can be challenging, and over- or under-parameterization may affect model stability and interpretability (@ryoo2011model). Additionally, while LMMs accommodate unbalanced data, reduced precision under distributional violations remains an important consideration (@schielzeth2020robustness).

Owing to their robust performance in the face of imperfect data, LMMs are commonly utilized in practical fields such as agriculture, psychology, ecology, and clinical research. @meteyard2020best documented their extensive adoption in psychological research, while agricultural applications include modeling spatial yield variation in plant breeding trials (@adhikari2016comparing) and assessing environmental drivers of winter wheat performance (@zhou2022using).

Within the present capstone project, LMMs provide an appropriate framework for modeling U.S. egg production across states and years while investigating the effects of average feed price and temperature. The repeated-measures and nested structure of the dataset necessitate an approach capable of partitioning population-level effects from state-level variability. By capturing both fixed interactions and hierarchical random variation, LMMs offer more comprehensive insights into production dynamics than traditional regression alone. 



## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{python}
import pandas as pd
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
ChatGPT-5.2 used to fine tune writing to improve grammar, sentence structure, and flow.

@meteyard2020best 
@brown2021introduction
@zhou2022using
@adhikari2016comparing
@ryoo2011model
@schielzeth2020robustness
@huitema2025fisher
@henderson1953variance
@NOAA_ClimateAtAGlance_2026
@USDA_ChickensAndEggs_2026
@USDA_AgriculturalPrices_2026